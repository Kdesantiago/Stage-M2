---
title: "R Notebook"
---

```{r}
#library(tensorr)
library(orthoDr)
library(pracma)
library(quadprog)
library(mixKernel)
```


```{r}
SCMK <- function(data,c=3,alpha=1,beta=1,gamma=1,mu=1,nb_etape=200,tol=1e-3){
    #data : tensor with dim(n,n,r) where data[:,:,k] is the kernel k on data
    # c : number of cluster 
    
    
    # Initialisation des variables 
    if(length(dim(data))==2){
        r = 1
        n = dim(data)[1]
    }
    else {
        r = dim(data)[3]
        n = dim(data)[1]
    }
    Z = matrix(runif(n*n,0,1),nrow=n,ncol=n)
    P = gramSchmidt( matrix(runif(n*c,0,1),nrow=n,ncol=c))$Q
    Q = gramSchmidt( matrix(runif(c*c,0,1),nrow=c,ncol=c))$Q
    F1 = P %*% Q
    
    list_argmax=max.col(F1)#donne liste indice du max par ligne
    for (i in 1:n){
        F1[i,list_argmax[i]] = 1
        F1[i,-list_argmax[i]] = 0
    }
    F_init=F1
    Y = matrix(0,nrow=n,ncol=n) # hésitation avec : Y=np.zeros((n,1)) vu le code matlab...
    w = matrix(1,nrow=r,ncol=1)/(r^2) ## On veut que sum(sqrt(w))=1
    
    etape=1
    
    
    S = matrix(0,nrow=n,ncol=n)
    h = matrix(1,nrow=r,ncol=1)
    
    while( (etape<nb_etape+1) & (base::norm(Z-S,type='F') > base::norm(Z,type='F')*tol) ){
        #print(etape)
        #''' Calcul de Kw '''
        Kw = matrix(0,nrow=n,ncol=n)
        
        if(r==1) {
            Kw = data
        }
        else {
            for (i in 1:r) Kw = Kw + w[i]*data[,,i]
        }

       #  Update de S 
         S = Z-Y/mu
         S[abs(S)<alpha/mu] = alpha/mu
         S = (abs(S)-alpha/mu) * sign(S)
         S = S-diag(diag(S))
         S[S<0]=0
        
       # Update de Z 
        E = S + Y/mu
        dist_p = (P^2) %*% matrix(1,nrow=c,ncol=n) - 2 * P %*% t(P) + matrix(1,nrow=n,ncol=c) %*% t(P^2) # ||P_i,: - P_j,:||^2
        tmp1 = mu*diag(n) + 2*Kw
        tmp2 = beta/2 * dist_p - 2* Kw - mu * E
        Z = solve(tmp1) %*% (-tmp2)
        Z = Z - diag(diag(Z))
        Z[Z<0] = 0
        Z = (Z+t(Z))/2
        
        # Update de Y 
        Y = Y + mu * (S-Z)
        
       #  Update de P 
        D = diag(rowSums(Z))
        L = D - Z
        args=list('L'=L,'F1'=F1,'Q'=Q,'beta'=beta,'gamma'=gamma)
        P = ortho_optim(P,fun,grad=grad,args= args,verbose = FALSE)$B
        
        # Update de Q 
        decomposition = svd(t(F1) %*% P)
        Q = decomposition$u %*% t(decomposition$v)
        
       #  Update de F 
        F1 = P %*% Q
        list_argmax=max.col(F1) #donne liste indice du max par ligne
        for (i in 1:n){
            F1[i,list_argmax[i]] = 1
            F1[i,-list_argmax[i]] = 0
        }
        if(r>1){
            #''' Calcul de h '''
            for (i in 1:r) h[i] = Trace( data[,,i] - 2*data[,,i]%*%Z + t(Z) %*% data[,,i] %*%Z )

            #''' Update de w '''
            for (i in 1 : r) w[i] = (h[i] * sum(1./h))^(-2)
        }
        etape=etape+1
        #print(dist_p)
    }
    #print(Z)
    #print(S)
    output=list("pred"=list_argmax,"Z"=Z,'K'=Kw,'w'=w,'P'=P,'F'=F1,'F_init'=F_init)
    return(output)
}
```


```{r}
Self_expressiveness <- function(data,alpha=1,mu=1,nb_etape=200,tol=1e-3){
    #data : tensor with dim(n,n,r) where data[:,:,k] is the kernel k on data
    # c : number of cluster 
    
    
    # Initialisation des variables 
    if(length(dim(data))==2){
        r = 1
        n = dim(data)[1]
    }
    else {
        r = dim(data)[3]
        n = dim(data)[1]
    }
    Z = matrix(runif(n*n,0,1),nrow=n,ncol=n)
    
    Y = matrix(0,nrow=n,ncol=n)
    w = matrix(1,nrow=r,ncol=1)/(r^2) ## On veut que sum(sqrt(w))=1
    
    etape=1
    
    
    S = matrix(0,nrow=n,ncol=n)
    h = matrix(1,nrow=r,ncol=1)
    
    while( (etape<nb_etape+1) & (base::norm(Z-S,type='F') > base::norm(Z,type='F')*tol) ){
        #print(etape)
        #''' Calcul de Kw '''
        Kw = matrix(0,nrow=n,ncol=n)
        
        if(r==1) {
            Kw = data
        }
        else {
            for (i in 1:r) Kw = Kw + w[i]*data[,,i]
        }

       #  Update de S 
         S = Z-Y/mu
         S[abs(S)<alpha/mu] = alpha/mu
         S = (abs(S)-alpha/mu) * sign(S)
         S = S-diag(diag(S))
         S[S<0]=0
        
       # Update de Z 
        E = S + Y/mu
        tmp1 = mu*diag(n) + 2*Kw
        tmp2 = - 2* Kw - mu * E
        Z = solve(tmp1) %*% (-tmp2)
        
        Z = Z - diag(diag(Z))
        Z[Z<0] = 0
        Z = (Z+t(Z))/2
        
        # Update de Y 
        Y = Y + mu * (S-Z)
        
        if(r>1){
            #''' Calcul de h '''
            for (i in 1:r) h[i] = Trace( data[,,i] - 2*data[,,i]%*%Z + t(Z) %*% data[,,i] %*%Z )

            #''' Update de w '''
            for (i in 1 : r) w[i] = (h[i] * sum(1./h))^(-2)
        }
        etape=etape+1
        #print(dist_p)
    }
    #print(Z)
    #print(S)
    output=list("Z"=Z,'K'=Kw,'w'=w)
    return(output)
}
```

```{r}
tmp = Self_expressiveness(data = data,alpha = 100,mu=1,nb_etape = 50,tol = 1e-3)
```


```{r}
image(x=1:200,y=1:200,z=tmp$Z)
```


```{r}
STATIS_UMKL<-function(data)
{
    r=dim(data)[3]
    # Construction de la matrice de similarité
    C=matrix(0,r,r)
    for (i in 1:r){
        for (j in 1:r){
            C[i,j]=Trace(data[,,i] %*% data[,,j])/sqrt(Trace(data[,,i] %*% data[,,i]) * Trace(data[,,j] %*% data[,,j]))
        }
    }
    # Optimisation des poids v
    v = eigen(C)$vectors[,1]
    v = v/sum(v)
    
    # Construction du noyau consensus K*
    K_star = matrix(0,dim(data)[1],dim(data)[1])
    for (i in 1:r){
            K_star = K_star + v[i] * data[,,i]
    }
    output=list('K' = K_star, 'w'=v)
    return(output)
}
```


```{r}
sparse_UMKL<-function(data,k)
{
    r = dim(data)[3]
    n = dim(data)[1]
    
    # Construction de W
    W = matrix(0,n,n)
    
    for (a in 1:r){
      for (i in 1:n){
          tmp = sort(data[i,,a])[n-(k-1)]
          W[i,data[i,,a]>tmp] = W[i,data[i,,a]>tmp] +1
      }
    }
    W = W + t(W)
    W = W - diag(diag(W))
    # Construction de S ( A optimiser, là c'est pour l'idée)
    S = matrix(0,r,r)
    for (m1 in 1:r){
        for( m2 in 1:r){
            for (i in 1:n){
                for( j in i:n){
                    S[m1,m2]=S[m1,m2] + W[i,j] * t(data[,i,m1]-data[,j,m1]) %*% (data[,i,m2]-data[,j,m2])
                }
            }
        }
    }
    # Optimisation des poids v
    tmp = quadprog(C=2*S, d=rep(0,r), Aeq = rep(1,r),beq = 1,lb=0,ub = 1)
    v = tmp$xmin
    
    # Construction du noyau consensus K*
    K_star = matrix(0,n,n)
    for (i in 1:r){
            K_star = K_star + v[i] * data[,,i]
    }
    output=list('K' = K_star, 'w'=v)
    return(output)
}
```


